{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d455391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project root (one level above notebooks/)\n",
    "ROOT = Path(__vsc_ipynb_file__).resolve().parent.parent if \"__vsc_ipynb_file__\" in dir() else Path.cwd().parent\n",
    "ARTIFACTS = ROOT / \"artifacts\"\n",
    "\n",
    "# Load dataset config\n",
    "with open(ROOT / \"configs\" / \"datasets.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "ref_name = cfg[\"reference\"][\"name\"]\n",
    "candidates = list(cfg[\"candidates\"].keys())\n",
    "\n",
    "def pretty(name):\n",
    "    \"\"\"Human-friendly dataset label.\"\"\"\n",
    "    return name.replace(\"_\", \"-\")\n",
    "\n",
    "print(f\"Reference : {pretty(ref_name)}\")\n",
    "print(f\"Candidates: {[pretty(c) for c in candidates]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Load embedding metadata ────────────────────────────────────────────────\n",
    "emb_stats = {}\n",
    "for name in [ref_name] + candidates:\n",
    "    meta_path = ARTIFACTS / \"embeddings\" / name / \"meta.json\"\n",
    "    if meta_path.exists():\n",
    "        with open(meta_path) as f:\n",
    "            emb_stats[name] = json.load(f)\n",
    "\n",
    "# ── Load retrieval similarities (1-NN) ─────────────────────────────────────\n",
    "retrieval_sims = {}\n",
    "for cand in candidates:\n",
    "    sim_path = ARTIFACTS / \"retrieval\" / f\"{ref_name}_{cand}\" / \"nn_sim.npy\"\n",
    "    if sim_path.exists():\n",
    "        retrieval_sims[cand] = np.load(sim_path)\n",
    "\n",
    "# ── Load aggregated weights ────────────────────────────────────────────────\n",
    "weights_dir = ARTIFACTS / \"weights\" / ref_name\n",
    "weights, counts = {}, {}\n",
    "if (weights_dir / \"weights.json\").exists():\n",
    "    with open(weights_dir / \"weights.json\") as f:\n",
    "        weights = json.load(f)\n",
    "    with open(weights_dir / \"counts.json\") as f:\n",
    "        counts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6323e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Summary table ──────────────────────────────────────────────────────────\n",
    "ref_count = emb_stats.get(ref_name, {}).get('count', 0)\n",
    "total_wins = sum(counts.get(c, 0) for c in candidates)\n",
    "\n",
    "cols = [(\"Dataset\", \"<15\"), (\"Size\", \">10\"), (\"Weight\", \">8\"),\n",
    "        (\"Mean Sim\", \">10\"), (\"Wins\", \">8\"), (\"Win %\", \">7\")]\n",
    "header = \"  \".join(f\"{name:{fmt}}\" for name, fmt in cols)\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for cand in candidates:\n",
    "    size = emb_stats.get(cand, {}).get('count', 0)\n",
    "    w = weights.get(cand, 0)\n",
    "    mean_sim = float(np.mean(retrieval_sims[cand])) if cand in retrieval_sims else 0\n",
    "    wins = counts.get(cand, 0)\n",
    "    win_pct = 100 * wins / total_wins if total_wins > 0 else 0\n",
    "    print(f\"{pretty(cand):<15}  {size:>10,}  {w:>8.3f}  {mean_sim:>10.4f}  {wins:>8,}  {win_pct:>6.1f}%\")\n",
    "\n",
    "print(f\"\\nReference: {pretty(ref_name)} ({ref_count:,} images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualizations ─────────────────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle(\"Dataset Weighting Analysis\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "n = len(candidates)\n",
    "x = np.arange(n)\n",
    "labels = [pretty(c) for c in candidates]\n",
    "\n",
    "# ── Plot 1: Dataset sizes vs assigned weights ──────────────────────────────\n",
    "ax = axes[0]\n",
    "sizes = [emb_stats.get(c, {}).get('count', 0) for c in candidates]\n",
    "w_vals = [weights.get(c, 0) for c in candidates]\n",
    "\n",
    "ax.bar(x - 0.2, sizes, 0.35, color=\"skyblue\", alpha=0.8, label=\"Size\")\n",
    "ax.set_ylabel(\"Dataset Size\", color=\"darkblue\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title(\"Sizes vs. Weights\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.bar(x + 0.2, w_vals, 0.35, color=\"coral\", alpha=0.8, label=\"Weight\")\n",
    "ax2.set_ylabel(\"Weight\", color=\"darkred\")\n",
    "\n",
    "h1, l1 = ax.get_legend_handles_labels()\n",
    "h2, l2 = ax2.get_legend_handles_labels()\n",
    "ax.legend(h1 + h2, l1 + l2, loc=\"upper left\", fontsize=8)\n",
    "ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# ── Plot 2: 1-NN similarity distributions ─────────────────────────────────\n",
    "ax = axes[1]\n",
    "sim_data = [retrieval_sims[c] for c in candidates if c in retrieval_sims]\n",
    "sim_labels = [pretty(c) for c in candidates if c in retrieval_sims]\n",
    "\n",
    "if sim_data:\n",
    "    vp = ax.violinplot(sim_data, showmeans=True, showmedians=True)\n",
    "    for body in vp[\"bodies\"]:\n",
    "        body.set_alpha(0.7)\n",
    "    ax.set_xticks(range(1, len(sim_labels) + 1))\n",
    "    ax.set_xticklabels(sim_labels)\n",
    "\n",
    "    for i, d in enumerate(sim_data):\n",
    "        ax.text(i + 1, ax.get_ylim()[1] * 0.95, f\"\\u03bc={np.mean(d):.3f}\",\n",
    "                ha=\"center\", va=\"top\", fontsize=9, fontweight=\"bold\",\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "ax.set_ylabel(\"Cosine Similarity\")\n",
    "ax.set_title(\"1-NN Similarity Distributions\")\n",
    "ax.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# ── Plot 3: Wins distribution ─────────────────────────────────────────────\n",
    "ax = axes[2]\n",
    "win_vals = [counts.get(c, 0) for c in candidates]\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, n))\n",
    "\n",
    "bars = ax.barh(x, win_vals, color=colors, edgecolor=\"black\", alpha=0.8)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel(\"Wins (query matches)\")\n",
    "ax.set_title(f\"Wins Distribution (n={total_wins:,})\")\n",
    "\n",
    "for cnt, bar in zip(win_vals, bars):\n",
    "    pct = 100 * cnt / total_wins if total_wins > 0 else 0\n",
    "    ax.text(bar.get_width() + total_wins * 0.01,\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f\"{cnt:,} ({pct:.1f}%)\", va=\"center\", fontsize=9)\n",
    "\n",
    "ax.grid(axis=\"x\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset_weighting_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
